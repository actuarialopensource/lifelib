{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyP21o9TrDToE5R0lRLzkBaO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Build your own decorator\n","\n","## Why decorators\n","\n","* Python already uses them to cache functions with `@functools.cache`\n","* At least three people are using them to build open source life insurance software.\n","    * https://github.com/fumitoh/modelx\n","    * https://github.com/acturtle\n","    * https://github.com/actuarialopensource/benchmarks\n","\n","\n","We assume you already know how decorators work. There is a great guide on [realpython](https://realpython.com/primer-on-python-decorators/). Let's discuss a couple of topic of interests."],"metadata":{"id":"siSPIDTTm0Qr"}},{"cell_type":"markdown","source":["## Clear the cache for all formulas at once\n","\n","As the number of formulas grows, we need to be able to clear all of the caches at the same time. This is not possible with `@functools.cache`.\n","\n"],"metadata":{"id":"38IMvEm8DCYW"}},{"cell_type":"code","execution_count":93,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XoWuZfC3mzfs","executionInfo":{"status":"ok","timestamp":1710029929698,"user_tz":360,"elapsed":124,"user":{"displayName":"Matthew Caseres","userId":"10689995415103500952"}},"outputId":"0056df3f-25a2-44d2-da3f-2a692b734b32"},"outputs":[{"output_type":"stream","name":"stdout","text":["dead(9)=0.00913517247483641\n","dead(9)=0.016674955242603\n"]}],"source":["from collections import defaultdict\n","from functools import wraps\n","\n","class CashBasic:\n","    def __init__(self):\n","        self.cache_clear()\n","\n","    def cache_clear(self):\n","        self.caches = {}\n","\n","    def __call__(self, func):\n","        @wraps(func)\n","        def wrapper(*args, **kwargs):\n","            key = (func, args, frozenset(kwargs.items()))\n","            if key not in self.caches:\n","                self.caches[key] = func(*args, **kwargs)\n","            return self.caches[key]\n","        return wrapper\n","\n","class Mortality:\n","    def __init__(self, mortality_rate):\n","        self.mortality_rate = mortality_rate\n","\n","mort = Mortality(.01)\n","\n","cash_basic = CashBasic()\n","\n","@cash_basic\n","def dead(t):\n","    return alive(t) * mort.mortality_rate\n","\n","@cash_basic\n","def alive(t):\n","    if t <= 0:\n","        return 1\n","    return alive(t-1) - dead(t-1)\n","\n","print(f\"{dead(9)=}\")\n","cash_basic.cache_clear() # We don't need to clear each function individually like with @functools.cache\n","mort.mortality_rate = .02\n","print(f\"{dead(9)=}\")\n"]},{"cell_type":"markdown","source":["## Clear unused cache values at runtime\n","\n","If we are certain that once we calculate certain a value for a timestep `t`no values from timestep`t-1` are necessary, we are able to clear the cache for timestep `t-1`.\n","\n","`modelx` has something similar to this. There are a lot of ways you can try to accomplish this, here we take an approach where users must manually clear the cache for a particular timestep.\n","\n","We will discuss this more later, but vectorizing calculations improves performance significantly. This comes at the cost of increased memory consumption, since the cached values are large vectors. The next example is vectorized using NumPy, and includes logic for calculating the memory consumption of the model.\n","\n"],"metadata":{"id":"TG8DhRTTFzwN"}},{"cell_type":"code","source":["from collections import defaultdict\n","from functools import wraps\n","import numpy as np\n","\n","class CashMemoryOptimized:\n","    def __init__(self):\n","        self.cache_clear()\n","\n","    def cache_clear(self):\n","        self.caches = defaultdict(dict)\n","        self.max_cache_size = 0\n","        self.cache_misses = 0\n","\n","    def get_cache_size(self):\n","        total = 0\n","        for timestep_cache in self.caches.values():\n","            for np_array in timestep_cache.values():\n","                total += np_array.nbytes\n","        self.max_cache_size = max(self.max_cache_size, total)\n","\n","    def cache_clear_at_timestep(self, t):\n","        del self.caches[t]\n","\n","    def __call__(self, func):\n","        @wraps(func)\n","        def wrapper(*args, **kwargs):\n","            key = (func, args, frozenset(kwargs.items()))\n","            has_timestep = (len(args) > 0) and type(args[0]) == int # We are assuming each function has an int timestep as first arg\n","            timestep_arg = args[0] if has_timestep else None\n","            if key not in self.caches[timestep_arg]:\n","                self.cache_misses += 1\n","                self.caches[timestep_arg][key] = func(*args, **kwargs)\n","                self.get_cache_size() # recalculate max cache size\n","            return self.caches[timestep_arg][key]\n","        return wrapper\n","\n","class Mortality:\n","    def __init__(self, mortality_rate):\n","        self.mortality_rate = mortality_rate\n","\n","mort = Mortality(np.linspace(.01, .02, 1000))\n","\n","cash_optimized = CashMemoryOptimized()\n","\n","@cash_optimized\n","def dead(t):\n","    return alive(t) * mort.mortality_rate\n","\n","@cash_optimized\n","def alive(t):\n","    if t <= 0:\n","        return np.ones(len(mort.mortality_rate))\n","    return alive(t-1) - dead(t-1)\n"],"metadata":{"id":"2Lb1xqYCHoog","executionInfo":{"status":"ok","timestamp":1710021854035,"user_tz":360,"elapsed":118,"user":{"displayName":"Matthew Caseres","userId":"10689995415103500952"}}},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":["Below we see over 99% reduction in memory usage is possible. The performance gains are larger than expected, unsure the reasoning behind that."],"metadata":{"id":"Tr43oTyLQ2k7"}},{"cell_type":"code","source":["import time\n","\n","max_timestep = 240\n","number_of_policies = 500_000\n","mort.mortality_rate = np.linspace(.01, .02, number_of_policies)\n","\n","print(f\"{number_of_policies=}\\n\")\n","\n","print(\"#### Unoptimized statistics ####\")\n","cash_optimized.cache_clear()\n","start_time_unoptimized = time.time()\n","result_unoptimized = np.sum(dead(max_timestep))\n","print(\"--- %s seconds ---\" % (time.time() - start_time_unoptimized))\n","start_time_unoptimized = time.time()\n","print(f\"{result_unoptimized=}\")\n","unoptimized_memory_consumption_in_bytes = cash_optimized.max_cache_size\n","print(f\"Memory consumption {unoptimized_memory_consumption_in_bytes/(10**9)} GB\")\n","print(f\"{cash_optimized.cache_misses=}\\n\")\n","\n","print(\"#### Optimized statistics ####\")\n","cash_optimized.cache_clear()\n","start_time_optimized = time.time()\n","for t in range(1,max_timestep+1):\n","    dead(t)\n","    cash_optimized.cache_clear_at_timestep(t-1)\n","result_optimized = np.sum(dead(max_timestep))\n","print(\"--- %s seconds ---\" % (time.time() - start_time_optimized))\n","print(f\"{result_optimized=}\")\n","optimized_memory_consumption_in_bytes = cash_optimized.max_cache_size\n","print(f\"Memory consumption {optimized_memory_consumption_in_bytes/(10**9)} GB\")\n","print(f\"{cash_optimized.cache_misses=}\")\n","\n","print(\"\\n#### Memory savings ####\")\n","print(f\"1 - optimized/unoptimized = {1-optimized_memory_consumption_in_bytes/unoptimized_memory_consumption_in_bytes}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"labcWT-CKyyK","executionInfo":{"status":"ok","timestamp":1710028973666,"user_tz":360,"elapsed":2912,"user":{"displayName":"Matthew Caseres","userId":"10689995415103500952"}},"outputId":"13b89c3d-f4b2-4b45-e4d9-84a45d4c3225"},"execution_count":92,"outputs":[{"output_type":"stream","name":"stdout","text":["number_of_policies=500000\n","\n","#### Unoptimized statistics ####\n","--- 1.906851053237915 seconds ---\n","result_unoptimized=221.0718846279971\n","Memory consumption 1.928 GB\n","cash_optimized.cache_misses=482\n","\n","#### Optimized statistics ####\n","--- 0.6406657695770264 seconds ---\n","result_optimized=221.0718846279971\n","Memory consumption 0.016 GB\n","cash_optimized.cache_misses=482\n","\n","#### Memory savings ####\n","1 - optimized/unoptimized = 0.991701244813278\n"]}]},{"cell_type":"markdown","source":["## Aggregate and store results at runtime\n","\n","If we are clearing cache values at runtime, we won't have immediate access to the cached values to generate tables with quantities like\n","\n","* `[np.sum(deaths(t)) for t in range(max_timesteps+1)]`\n","* `[np.sum(alive(t)) for t in range(max_timesteps+1)]`\n","\n","Let's look at one way to do this."],"metadata":{"id":"zEtjtW6XrKtg"}},{"cell_type":"code","source":["from collections import defaultdict\n","from functools import wraps\n","import pandas as pd\n","\n","class CashAggregated:\n","    def __init__(self):\n","        self.cache_clear()\n","\n","    def cache_clear(self):\n","        self.caches = {}\n","        self.stored_values = defaultdict(dict)\n","\n","    def __call__(self, storage_func=None):\n","        def decorator_factory(func):\n","            @wraps(func)\n","            def wrapper(*args, **kwargs):\n","                key = (func, args, frozenset(kwargs.items()))\n","                if key not in self.caches:\n","                    self.caches[key] = func(*args, **kwargs)\n","                if not storage_func is None:\n","                    self.stored_values[func.__name__][args[0]] = storage_func(self.caches[key])\n","                return self.caches[key]\n","            return wrapper\n","        return decorator_factory\n","\n","mort = Mortality(.01 * np.ones(1000))\n","\n","cash_aggregated = CashAggregated()\n","\n","@cash_aggregated(lambda x: np.sum(x))\n","def dead(t):\n","    return alive(t) * mort.mortality_rate\n","\n","@cash_aggregated(lambda x: np.sum(x))\n","def alive(t):\n","    if t <= 0:\n","        return np.ones(len(mort.mortality_rate))\n","    return alive(t-1) - dead(t-1)\n","\n","dead(10)\n","pd.DataFrame(cash_aggregated.stored_values)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":394},"id":"VJZYorbr8HWi","executionInfo":{"status":"ok","timestamp":1710030662429,"user_tz":360,"elapsed":140,"user":{"displayName":"Matthew Caseres","userId":"10689995415103500952"}},"outputId":"574ac73c-0a5c-4c1c-9b07-2e97e596d52f"},"execution_count":100,"outputs":[{"output_type":"execute_result","data":{"text/plain":["          alive       dead\n","0   1000.000000  10.000000\n","1    990.000000   9.900000\n","2    980.100000   9.801000\n","3    970.299000   9.702990\n","4    960.596010   9.605960\n","5    950.990050   9.509900\n","6    941.480149   9.414801\n","7    932.065348   9.320653\n","8    922.744694   9.227447\n","9    913.517247   9.135172\n","10   904.382075   9.043821"],"text/html":["\n","  <div id=\"df-54565db4-091c-4047-8ddf-48cba4d125da\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>alive</th>\n","      <th>dead</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1000.000000</td>\n","      <td>10.000000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>990.000000</td>\n","      <td>9.900000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>980.100000</td>\n","      <td>9.801000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>970.299000</td>\n","      <td>9.702990</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>960.596010</td>\n","      <td>9.605960</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>950.990050</td>\n","      <td>9.509900</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>941.480149</td>\n","      <td>9.414801</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>932.065348</td>\n","      <td>9.320653</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>922.744694</td>\n","      <td>9.227447</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>913.517247</td>\n","      <td>9.135172</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>904.382075</td>\n","      <td>9.043821</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54565db4-091c-4047-8ddf-48cba4d125da')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-54565db4-091c-4047-8ddf-48cba4d125da button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-54565db4-091c-4047-8ddf-48cba4d125da');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-20e7741c-412c-4a7b-8a98-d1e2e43fa8dd\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-20e7741c-412c-4a7b-8a98-d1e2e43fa8dd')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-20e7741c-412c-4a7b-8a98-d1e2e43fa8dd button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"pd\",\n  \"rows\": 11,\n  \"fields\": [\n    {\n      \"column\": \"alive\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 31.71215740266099,\n        \"min\": 904.3820750088046,\n        \"max\": 1000.0,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          950.9900498999998,\n          1000.0,\n          913.5172474836411\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dead\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3171215740266094,\n        \"min\": 9.043820750088045,\n        \"max\": 10.0,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          9.509900498999999,\n          10.0,\n          9.135172474836413\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":100}]},{"cell_type":"markdown","source":["## Summary\n","\n","* You will certainly want to be able to clear the cache for all formulas at once.\n","* It would be nice if you could limit memory consumption. This is most easily accomplished if all formulas at timestep `t` only depend on timestep `t-1`.\n","* You can aggregate a result when it is calculated and store it in a special format for displaying it later."],"metadata":{"id":"Hv69BSeqzxlG"}}]}